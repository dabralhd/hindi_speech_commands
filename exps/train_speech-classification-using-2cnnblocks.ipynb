{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.11 64-bit ('mlflow': conda)"},"language_info":{"name":"python","version":"3.8.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"c13d9a85dff95a868edbcf0a8765019facc546e79a69ab41799711a8533c33c2"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# [2,4] CNN blocks neural network for classifying google-speech command dataset\n","\n","based on 2 conv blocks only"],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["from os.path import isdir, join\n","from pathlib import Path\n","import pandas as pd\n","\n","# Math\n","import numpy as np\n","from scipy.fftpack import fft\n","from scipy import signal\n","from scipy.io import wavfile\n","import librosa\n","\n","from sklearn.decomposition import PCA\n","\n","import plotly.offline as py\n","py.init_notebook_mode(connected=True)\n","import plotly.graph_objs as go\n","import plotly.tools as tls\n","import pandas as pd\n","\n","import argparse\n","import sys\n","from mlflow import pyfunc\n","import mlflow.tensorflow\n","\n","import os\n","from scipy.io import wavfile #for audio processing\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import backend as K\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","from tensorflow.keras.utils import to_categorical \n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","import tensorflow as tf\n","\n","print(tf.__version__)"],"outputs":[{"output_type":"display_data","data":{"text/html":["        <script type=\"text/javascript\">\n","        window.PlotlyConfig = {MathJaxConfig: 'local'};\n","        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n","        if (typeof require !== 'undefined') {\n","        require.undef(\"plotly\");\n","        requirejs.config({\n","            paths: {\n","                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n","            }\n","        });\n","        require(['plotly'], function(Plotly) {\n","            window._Plotly = Plotly;\n","        });\n","        }\n","        </script>\n","        "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["2.4.0\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-17T07:52:14.280629Z","iopub.execute_input":"2021-08-17T07:52:14.280993Z","iopub.status.idle":"2021-08-17T07:52:16.365696Z","shell.execute_reply.started":"2021-08-17T07:52:14.280957Z","shell.execute_reply":"2021-08-17T07:52:16.364870Z"},"trusted":true}},{"cell_type":"code","execution_count":2,"source":["def load_data(train_audio_path, labels):\n","    #train_audio_path = '/home/hem/work/machine-learning/ignore/speech_commands_v0.02'\n","\n","    all_wave = []\n","    all_label = []\n","    for label in labels:\n","        #print(label)\n","        waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n","        for wav in waves:\n","            samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 16000)\n","            samples = librosa.resample(samples, sample_rate, 8000)\n","            if(len(samples)== 8000): \n","                samples = np.expand_dims(samples, axis=-1)\n","                all_wave.append(samples)\n","                all_label.append(label)\n","                \n","    return all_wave, all_label"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-17T06:59:38.762579Z","iopub.status.idle":"2021-08-17T06:59:38.763372Z"},"trusted":true}},{"cell_type":"code","execution_count":3,"source":["def get_train_test_data(all_wave, all_label):\n","    assert (len(all_wave) == len(all_label))\n","    \n","    le = LabelEncoder()\n","    y=le.fit_transform(all_label)\n","    classes= list(le.classes_)\n","\n","    print('number of classes: {}'.format(len(classes)))\n","\n","    y = to_categorical(y, num_classes=len(classes))\n","\n","    x_tr, x_val, y_tr, y_val = train_test_split(np.array(all_wave),np.array(y),stratify=y,test_size = 0.2,random_state=777,shuffle=True)\n","\n","    return (x_tr, y_tr), (x_val, y_val)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["def get_train_val_test_data(all_wave, all_label):\n","    assert (len(all_wave) == len(all_label))\n","\n","    le = LabelEncoder()\n","    y=le.fit_transform(all_label)\n","    classes= list(le.classes_)\n","\n","    y = to_categorical(y, num_classes=len(all_label))\n","\n","    random_seq = np.random.permutation(len(all_wave))\n","    \n","    # first 70% for training set\n","    train_idx = random_seq[:0.7*len(all_wave)] \n","\n","     # next 20% for validation set   \n","    val_idx = random_seq[0.7*len(all_wave):0.9*len(all_wave)]\n","\n","    # rest everything for test set\n","    test_idx = random_seq[0.9*len(all_wave):]  \n","\n","    training_set = all_wave[train_idx], all_label[train_idx]\n","    validation_set = all_wave[val_idx], all_label[val_idx]\n","    test_set = all_wave[test_idx], all_label[test_idx]\n","\n","    return training_set, validation_set, test_set"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["def get_2cnn_blocks_model(all_label):\n","    K.clear_session()\n","\n","    inputs = Input(shape=(8000,1))\n","\n","    #First Conv1D layer\n","    conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)\n","    conv = MaxPooling1D(3)(conv)\n","    conv = Dropout(0.2)(conv)\n","\n","    #Second Conv1D layer\n","    conv = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(conv)\n","    conv = MaxPooling1D(3)(conv)\n","    conv = Dropout(0.2)(conv)\n","\n","    #Flatten layer\n","    conv = Flatten()(conv)\n","\n","    #Dense Layer 1\n","    conv = Dense(256, activation='relu')(conv)\n","    conv = Dropout(0.2)(conv)\n","\n","    #Dense Layer 2\n","    conv = Dense(128, activation='relu')(conv)\n","    conv = Dropout(0.2)(conv)\n","\n","    outputs = Dense(len(all_label), activation='softmax')(conv)\n","\n","    model = Model(inputs, outputs)\n","    model.summary()\n","    return model"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-17T06:59:38.774133Z","iopub.status.idle":"2021-08-17T06:59:38.774899Z"},"trusted":true}},{"cell_type":"code","execution_count":6,"source":["def get_sequential_2cnn_blocks_model(labels):\n","    K.clear_session()\n","\n","    model = tf.keras.Sequential()\n","\n","    model.add(Input(shape=(8000,1)))\n","\n","    #First Conv1D layer\n","    model.add(Conv1D(8,13, padding='valid', activation='relu', strides=1))\n","    model.add(MaxPooling1D(3))\n","    model.add(Dropout(0.2))\n","\n","    #Second Conv1D layer\n","    model.add(Conv1D(16, 11, padding='valid', activation='relu', strides=1))\n","    model.add(MaxPooling1D(3))\n","    model.add(Dropout(0.2))\n","\n","    #Flatten layer\n","    model.add(Flatten())\n","\n","    #Dense Layer 1\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dropout(0.2))\n","\n","    #Dense Layer 2\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dropout(0.2))\n","\n","    model.add(Dense(len(labels), activation='softmax'))\n","\n","    model.summary()\n","    return model"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["def get_4cnn_blocks_model(all_label):\n","    K.clear_session()\n","\n","    inputs = Input(shape=(8000,1))\n","\n","    #First Conv1D layer\n","    conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)\n","    conv = MaxPooling1D(3)(conv)\n","    conv = Dropout(0.2)(conv)\n","\n","    #Second Conv1D layer\n","    conv = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(conv)\n","    conv = MaxPooling1D(3)(conv)\n","    conv = Dropout(0.2)(conv)\n","\n","    #Third Conv1D layer\n","    conv = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(conv)\n","    conv = MaxPooling1D(3)(conv)\n","    conv = Dropout(0.2)(conv)\n","\n","    #Fourth Conv1D layer\n","    conv = Conv1D(64, 7, padding='valid', activation='relu', strides=1)(conv)\n","    conv = MaxPooling1D(3)(conv)\n","    conv = Dropout(0.2)(conv)\n","\n","    #Flatten layer\n","    conv = Flatten()(conv)\n","\n","    #Dense Layer 1\n","    conv = Dense(256, activation='relu')(conv)\n","    conv = Dropout(0.2)(conv)\n","\n","    #Dense Layer 2\n","    conv = Dense(128, activation='relu')(conv)\n","    conv = Dropout(0.2)(conv)\n","\n","    outputs = Dense(len(labels), activation='softmax')(conv)\n","\n","    model = Model(inputs, outputs)\n","\n","    model.summary()\n","    return model"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["def train_model(model, tr_data, val_data):\n","    x_tr, y_tr = tr_data\n","    x_val, y_val = val_data\n","    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.0001) \n","    mc = ModelCheckpoint('best_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n","    history = model.fit(x_tr, y_tr ,epochs=25, callbacks=[es,mc], batch_size=32, validation_data=(x_val,y_val))\n","    model.save('sequential_2cnn_blocks_model.h5')\n","    return history"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-17T06:59:38.777999Z","iopub.status.idle":"2021-08-17T06:59:38.778751Z"},"trusted":true}},{"cell_type":"code","execution_count":9,"source":["def predict(audio):\n","    prob=model.predict(audio.reshape(1,8000,1))\n","    index=np.argmax(prob[0])\n","    return classes[index]"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-17T06:59:38.783516Z","iopub.status.idle":"2021-08-17T06:59:38.784233Z"},"trusted":true}},{"cell_type":"code","execution_count":10,"source":["# Enable auto-logging to MLflow to capture TensorBoard metrics.\n","mlflow.tensorflow.autolog()\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\"--batch_size\", default=100, type=int, help=\"batch size\")\n","parser.add_argument(\"--train_steps\", default=1000, type=int, help=\"number of training steps\")\n","\n","def main():\n","    with mlflow.start_run():\n","        #args = parser.parse_args(argv[1:])\n","        train_audio_path = '/home/hem/work/machine-learning/ignore/speech_commands_v0.02'\n","        labels = ['yes', 'no','up','down','left','right','on','off','stop','go']\n","        #labels = ['yes', 'no']\n","\n","        all_wave, all_label = load_data(train_audio_path, labels)\n","        all_wave = tf.convert_to_tensor(all_wave)\n","        all_label = tf.convert_to_tensor(all_label)\n","\n","        print(all_wave.shape)\n","        print(all_label.shape)\n","\n","        tr_data, val_data = get_train_test_data(all_wave, all_label)\n","\n","        print('tr data x shape: {}'.format(tr_data[0].shape))\n","        print('tr data y shape: {}'.format(tr_data[1].shape))\n","\n","        print('val data x shape: {}'.format(val_data[0].shape))\n","        print('val data y shape: {}'.format(val_data[1].shape))    \n","\n","        model = get_sequential_2cnn_blocks_model(labels)\n","        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])    \n","\n","        history = train_model(model, tr_data, val_data)\n","\n","        # evaluate the model\n","\n","        # Generate predictions from the model"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["main()"],"outputs":[{"output_type":"stream","name":"stdout","text":["(34975, 8000, 1)\n","(34975,)\n","number of classes: 10\n","tr data x shape: (27980, 8000, 1)\n","tr data y shape: (27980, 10)\n","val data x shape: (6995, 8000, 1)\n","val data y shape: (6995, 10)\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv1d (Conv1D)              (None, 7988, 8)           112       \n","_________________________________________________________________\n","max_pooling1d (MaxPooling1D) (None, 2662, 8)           0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 2662, 8)           0         \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, 2652, 16)          1424      \n","_________________________________________________________________\n","max_pooling1d_1 (MaxPooling1 (None, 884, 16)           0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 884, 16)           0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 14144)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               3621120   \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 3,656,842\n","Trainable params: 3,656,842\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/25\n","875/875 [==============================] - 64s 72ms/step - loss: 1.9944 - accuracy: 0.2555 - val_loss: 1.3248 - val_accuracy: 0.5440\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 2/25\n","875/875 [==============================] - 65s 74ms/step - loss: 1.1225 - accuracy: 0.5994 - val_loss: 0.8353 - val_accuracy: 0.7162\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 3/25\n","875/875 [==============================] - 65s 74ms/step - loss: 0.7745 - accuracy: 0.7303 - val_loss: 0.7327 - val_accuracy: 0.7580\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 4/25\n","875/875 [==============================] - 63s 72ms/step - loss: 0.5739 - accuracy: 0.7987 - val_loss: 0.6878 - val_accuracy: 0.7728\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 5/25\n","875/875 [==============================] - 67s 76ms/step - loss: 0.4592 - accuracy: 0.8399 - val_loss: 0.7042 - val_accuracy: 0.7760\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 6/25\n","875/875 [==============================] - 65s 75ms/step - loss: 0.3754 - accuracy: 0.8677 - val_loss: 0.6855 - val_accuracy: 0.7870\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 7/25\n","875/875 [==============================] - 59s 68ms/step - loss: 0.3115 - accuracy: 0.8921 - val_loss: 0.7888 - val_accuracy: 0.7630\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 8/25\n","875/875 [==============================] - 58s 66ms/step - loss: 0.2724 - accuracy: 0.9066 - val_loss: 0.7638 - val_accuracy: 0.7926\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 9/25\n","875/875 [==============================] - 65s 74ms/step - loss: 0.2312 - accuracy: 0.9198 - val_loss: 0.8418 - val_accuracy: 0.7758\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 10/25\n","875/875 [==============================] - 64s 73ms/step - loss: 0.2280 - accuracy: 0.9238 - val_loss: 0.8732 - val_accuracy: 0.7758\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 11/25\n","875/875 [==============================] - 73s 83ms/step - loss: 0.2032 - accuracy: 0.9316 - val_loss: 0.8112 - val_accuracy: 0.7880\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 12/25\n","875/875 [==============================] - 66s 75ms/step - loss: 0.1727 - accuracy: 0.9423 - val_loss: 0.9310 - val_accuracy: 0.7803\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 13/25\n","875/875 [==============================] - 69s 79ms/step - loss: 0.1577 - accuracy: 0.9487 - val_loss: 0.9065 - val_accuracy: 0.7811\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 14/25\n","875/875 [==============================] - 67s 77ms/step - loss: 0.1509 - accuracy: 0.9487 - val_loss: 0.9287 - val_accuracy: 0.7886\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 15/25\n","875/875 [==============================] - 68s 77ms/step - loss: 0.1305 - accuracy: 0.9584 - val_loss: 0.9684 - val_accuracy: 0.7794\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 16/25\n","875/875 [==============================] - 68s 78ms/step - loss: 0.1360 - accuracy: 0.9561 - val_loss: 0.9858 - val_accuracy: 0.7708\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 00016: early stopping\n","INFO:tensorflow:Assets written to: /tmp/tmpikjdv163/model/data/model/assets\n"]}],"metadata":{}}]}